# AI_ACT_checklist

| **Requirement**                        | **Description**                                                                                       | **Example**                                                                                                  | **Completed (Y/N)** |
|----------------------------------------|-------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------------------|--------------------|
| **1. Risk Management System**          | Implement a risk management process to identify, assess, and mitigate risks throughout the AI lifecycle.| Setting up a system to regularly test the AI model's predictions for potential biases or inaccuracies.        |                    |
| **2. High-Quality Data Governance**    | Ensure training, validation, and testing data is representative, relevant, and free from bias.          | Using diverse datasets to avoid bias in an AI system used for hiring decisions.                               |                    |
| **3. Technical Documentation**         | Prepare detailed documentation on system design, development, testing, and data usage.                  | Creating a comprehensive document outlining how the AI model was developed, including all datasets used.       |                    |
| **4. Record Keeping and Logging**      | Maintain operational logs to enable traceability of the AI system’s decision-making processes.          | Storing logs of AI system inputs and outputs in a fraud detection model to trace how decisions were made.      |                    |
| **5. Transparency and User Information**| Provide clear instructions to users, including the system's purpose, risks, and limitations.            | Providing users of a healthcare AI system with a manual outlining the system’s intended use and potential risks.|                    |
| **6. Human Oversight**                 | Include mechanisms for human intervention, ensuring that users can monitor and override the AI system.  | Allowing a human operator to review and override decisions made by an AI system in autonomous driving.         |                    |
| **7. Robustness, Accuracy, and Security**| Ensure the system is robust, accurate, secure, and tested against adversarial attacks.                  | Implementing cybersecurity measures to protect an AI system used in facial recognition from hacking attempts.   |                    |
| **8. Conformity Assessment**           | Perform a conformity assessment to ensure the system meets AI Act standards before deployment.           | Conducting internal tests or hiring a third party to validate that an AI system in law enforcement is compliant.|                    |
| **9. Post-Market Monitoring**          | Set up post-market monitoring to continuously assess the AI system’s performance and safety.            | Continuously tracking a medical diagnosis AI system for errors or biases in real-world usage.                  |                    |
| **10. Reporting Serious Incidents**    | Establish a procedure to report serious incidents or malfunctions to relevant authorities.              | Setting up an incident reporting mechanism for an AI-powered surgical robot in case of malfunctions.           |                    |
| **11. Compliance of AI Components**    | Ensure all AI components (data, software, third-party services) comply with the AI Act’s requirements.  | Verifying that external datasets used in a credit scoring AI system are compliant with the required standards.  |                    |
| **12. CE Marking and Declaration of Conformity** | Obtain CE marking by performing a conformity assessment and issuing a declaration of compliance.        | Displaying the CE mark on an AI-powered medical device that has passed regulatory assessments.                 |                    |
